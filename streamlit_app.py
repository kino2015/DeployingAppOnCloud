# streamlit_app.py

import streamlit as st
import numpy as np
import cv2 # OpenCVã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯å¿…é ˆ
import onnxruntime as ort # ONNXãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯å¿…é ˆ

# ----------------- ãƒ¢ãƒ‡ãƒ«ã¨é–¢æ•°ã®å®šç¾© (cv_web_app.pyã‹ã‚‰ç§»æ¤) -----------------

# ONNXãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
try:
    # å®Ÿéš›ã«ã¯ã€ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® 'model.onnx' ã‚’èª­ã¿è¾¼ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™
    # Streamlit Cloudã§ã¯ã€GitHubã®ãƒ«ãƒ¼ãƒˆã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›¸å¯¾ãƒ‘ã‚¹ã§èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    session = ort.InferenceSession("model.onnx")
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop() # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚‰ã‚¢ãƒ—ãƒªã®å®Ÿè¡Œã‚’åœæ­¢

def process_image(img_data):
    # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’OpenCVå½¢å¼ã«å¤‰æ›
    np_img = np.frombuffer(img_data.read(), np.uint8)
    image = cv2.imdecode(np_img, cv2.IMREAD_GRAYSCALE)
    
    # ç”»åƒã‚’28x28ã«ãƒªã‚µã‚¤ã‚ºã—ã€ONNXãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›å½¢å¼ã«æ•´å½¢
    resized_image = cv2.resize(image, (28, 28), interpolation=cv2.INTER_AREA)
    # åè»¢ï¼ˆç™½é»’ï¼‰ã€æ­£è¦åŒ– (0-1)ã€å½¢çŠ¶å¤‰æ›´ (1, 1, 28, 28)
    preprocessed_image = 1 - (resized_image / 255.0) 
    input_tensor = preprocessed_image.reshape(1, 1, 28, 28).astype(np.float32)

    return input_tensor, resized_image

# ----------------- Streamlit UI -----------------

st.title("ğŸ”¢ Digit Recognizer (Streamlit)")
st.subheader("Upload an image of a handwritten digit (0-9)")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
uploaded_file = st.file_uploader("Choose a file...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    # å‡¦ç†ã®å®Ÿè¡Œ
    with st.spinner('Processing image and predicting...'):
        # ç”»åƒã®å‰å‡¦ç†
        input_tensor, display_img = process_image(uploaded_file)
        
        # ONNXãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬
        input_dict = {input_name: input_tensor}
        raw_output = session.run([output_name], input_dict)[0]
        
        # äºˆæ¸¬çµæœã®è§£é‡ˆ
        predicted_digit = np.argmax(raw_output)
        confidence = np.max(raw_output)
        
    # çµæœã®è¡¨ç¤º
    st.image(display_img, caption="Processed Image (28x28)", width=150)
    
    st.success(f"Recognized Digit: {predicted_digit}")
    st.info(f"Confidence: {confidence:.4f}")

    # è©³ç´°ãªãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if st.checkbox('Show Raw Predictions'):
        st.write(raw_output)

# ----------------------------------------------------